{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to analyse biomechanics data\n",
    "## 04/10/2021\n",
    "### Required python version: 3.6 \n",
    "\n",
    "The following is a notebook that will carry out the biomechanics analysis for a single .csv file (can also accept .xlsx as input). It needs to be ran in the folder the data is in. \n",
    "<br>Required packages: os, pandas, numpy, terminaltables, sys, re, xlrd, matplotlib. Most installations of Anaconda will include pandas and numpy.\n",
    "<br>Terminal tables from: https://anaconda.org/conda-forge/terminaltables\n",
    "<br>\n",
    "<br>If any packages aren't installed use package manager (preferably anaconda) to install, e.g.\n",
    "```\n",
    "conda install -c conda-forge terminaltables\n",
    "```\n",
    "<br>Contact Emily Johnson at ejohn16@liv.ac.uk or em.j.johnson.93@gmail.com if you're having trouble getting this notebook to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys \n",
    "import re\n",
    "import xlrd\n",
    "from terminaltables import AsciiTable\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create an empty dataframe for all the summary data to be saved to. This is less relevant when only analysing a single sample but in the batch script version it may contain thousands of samples. \n",
    "\n",
    "The results of this single sample analysis could be appended manually to a spreadsheet containing hundreds/thousands of samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sample_summary = pd.DataFrame(columns=\n",
    "    ['File name', 'Date', 'Sample ID', 'Replicate number', 'Sex', 'Age', 'Genotype', \n",
    "    'Sample length', 'Minimum force', 'Maximum force', 'Maximum force cycle 1', 'Maximum force cycle 5', 'Stress-relaxation', 'Rate of change of stress',\n",
    "    'Hysteresis sum value', 'Hysteresis %', 'Smoothed hysteresis sum value', 'Smoothed hysteresis %', \n",
    "    'Average diameter', 'Circumference', 'Circumference, true', 'Max modulus', 'Stress at max modulus', 'Strain at max modulus', 'Failure stress (MPa)',\n",
    "    'Failure strain (%)', 'Failure force (N)', 'Failure extension (mm)', 'Failure time (s)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A requirement for this notebook to run is a file containing all the meta-data for all the various samples: 'tendon_data_formatted.csv'. This processed meta-data file was created using the script 'format_sample_data.py', which extracted all the data from individual sheets and collated them into a flat .csv file. The original raw meta-data was in a file called 'Tm1b+oim Tendon Diameter +sampleInfo_270721.2.xlsx'. Thus, the next step is to check the processed meta-data file is accessible in the folder you're running the analysis in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking to see if formatted sample meta-data file 'tendon_data_formatted.csv' is present in analysis directory...\n",
      "Sample meta-data file found! Proceeding with analysis...\n"
     ]
    }
   ],
   "source": [
    "# Get current working directory \n",
    "dir = os.getcwd()\n",
    "\n",
    "# Check sample information file exists \n",
    "print(\"Checking to see if formatted sample meta-data file 'tendon_data_formatted.csv' is present in analysis directory...\")\n",
    "\n",
    "if os.path.isfile(\"tendon_data_formatted.csv\"):\n",
    "    print(\"Sample meta-data file found! Proceeding with analysis...\")\n",
    "    metadata = pd.read_csv(\"./tendon_data_formatted.csv\", header=0)\n",
    "    metadata = metadata.applymap(str)\n",
    "\n",
    "else:\n",
    "    sys.exit(\"Meta-data not found! Please make sure 'tendon_data_formatted.csv' is present in the same directory as the data. Terminating analysis...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the file you want to analyse to the variable 'file'. This can be a .csv file or a .xlsx file but a .csv file should be used by preference because they're quicker to read in.\n",
    "\n",
    "To read in an .xlsx file run: \n",
    "```\n",
    "file = str(\"210409 MRC Sample A1Data.xlsx\")\n",
    "df = pd.read_excel(\"{}\".format(file), index_col=None, header=0)  \n",
    "```\n",
    "\n",
    "To read in a .csv file run:\n",
    "```\n",
    "df = pd.read_csv(\"210409 MRC Sample A1Data.csv\", header=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"210409 MRC Sample A1Data.csv\", header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The individual sample meta-data is extracted by pairing the file name to data in the meta-data file. To do this the file name is first divided into seperate variables, then these variables are used to locate the row containing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = os.path.splitext(file)[0]\n",
    "excel_annotation = re.split('(\\d+)', name)\n",
    "sampleID = excel_annotation[2][-1]\n",
    "dateID = excel_annotation[1]\n",
    "replicateID = excel_annotation[3]\n",
    "sample_metadata = metadata.loc[(metadata.Date_ID == dateID) & (metadata.Sample_ID == sampleID) & (metadata.Replicate == replicateID)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, individual data frames are created for each stage of the tendon rupture experiment: pre-conditioning, stress-relaxation, failure.\n",
    "\n",
    "You might consider these individual data frames the equivalent of the spreadsheets in the original excel anaylsis. \n",
    "\n",
    "To extract each data frame the column 'setname' is searched for a string matching the stage of the rupture experiment and each row matching the string is assigned to the new data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "precon = df[df['SetName'].str.contains('5x pre-conditioning')]\n",
    "stressrelax = df[df['SetName'].str.contains('Stress-relax')]\n",
    "failure = df[df['SetName'].str.contains('Failure')]\n",
    "\n",
    "# df.iloc[:, 0:1] could also be used to select column 'SetName'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the analysis is carried out for the pre-conditioning, stress-relaxation and failure data following the SOP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejohn16/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/ejohn16/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ejohn16/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/ejohn16/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/home/ejohn16/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "## Pre-conditioning analysis - normalise/correct data\n",
    "\n",
    "# Minimum force\n",
    "minf = precon['Force_N'].min()\n",
    "\n",
    "# Sample length\n",
    "sample_length = precon.iloc[0,3]\n",
    "\n",
    "# Load correction\n",
    "precon['Load_correction'] = precon['Force_N'] - minf \n",
    "# Alternative: \n",
    "#precon['Load_correction'] = precon.iloc[:, 5] - minf\n",
    "\n",
    "# Displacement correction \n",
    "precon['Displacement_correction'] = precon['Displacement_mm'] - minf \n",
    "# Alternative: \n",
    "#precon['Displacement_correction'] = precon.iloc[:, 4] - minf\n",
    "\n",
    "# Area under curve\n",
    "for j in range(0,precon.shape[0]-1):\n",
    "    precon.loc[precon.index[j],'Area_under_curve'] = (0.1*(precon.iloc[j+1,6] + precon.iloc[j,6])*(precon.iloc[j+1,7] - precon.iloc[j,7]))\n",
    "\n",
    "# Load correction smooth \n",
    "precon['Load_correction_smoothed'] = precon['Load_correction'].rolling(window=5).mean()\n",
    "\n",
    "# Area under curve smooth\n",
    "for j in range(0,precon.shape[0]-1):\n",
    "    precon.loc[precon.index[j],'Area_under_curve_smooth'] = (0.1*(precon.iloc[j+1,9] + precon.iloc[j,9])*(precon.iloc[j+1,7] - precon.iloc[j,7]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-conditioning analysis - stress relaxation\n",
    "\n",
    "# Max force\n",
    "maxforce = precon['Force_N'].max()\n",
    "\n",
    "# Max force cycle 1 and cycle 5 \n",
    "maxforce_c1 = precon.loc[precon.Cycle.str.contains('1'), 'Force_N'].max()\n",
    "maxforce_c5 = precon.loc[precon.Cycle.str.contains('5'), 'Force_N'].max()\n",
    "\n",
    "# Stress-relaxation \n",
    "stress_relaxation = (((maxforce_c1-maxforce_c5)/maxforce_c1)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-conditioning analysis  - hysteresis \n",
    "\n",
    "# Hysteresis\n",
    "# Sum of beginning of cycle 1 to last positive value in cycle 1\n",
    "hysteresis_positive = precon.loc[(precon.Cycle.str.contains('1')) & (precon['Area_under_curve'] > 0), 'Area_under_curve'].sum()\n",
    "# Sum of first negative value in cycle 5 to last negative value in cycle 5\n",
    "hysteresis_negative = precon.loc[(precon.Cycle.str.contains('5')) & (precon['Area_under_curve'] < 0), 'Area_under_curve'].sum()\n",
    "# Add the two together to calculate sum value\n",
    "hysteresis_sum = hysteresis_positive + hysteresis_negative\n",
    "# Then calculate percentage\n",
    "percentage = (hysteresis_sum/hysteresis_positive)*100\n",
    "\n",
    "\n",
    "# Hysteresis smooth \n",
    "# Repeat the same process but for the smoothed area under the curve values\n",
    "smooth_hysteresis_positive = precon.loc[(precon.Cycle.str.contains('1')) & (precon['Area_under_curve_smooth'] > 0), 'Area_under_curve_smooth'].sum()\n",
    "smooth_hysteresis_negative = precon.loc[(precon.Cycle.str.contains('5')) & (precon['Area_under_curve_smooth'] < 0), 'Area_under_curve_smooth'].sum()\n",
    "smooth_hysteresis_sum = hysteresis_positive + hysteresis_negative\n",
    "smooth_percentage = (hysteresis_sum/hysteresis_positive)*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stress-relaxation analysis is simple and only consists of one calculation across the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stress-relaxation analysis \n",
    "\n",
    "stress_rate = ((stressrelax.iloc[0,5] - stressrelax.iloc[6000,5])/60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the failure analysis the data first needs to be normalised/corrected. \n",
    "This step requires the circumference data from the metadata file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejohn16/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/ejohn16/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/ejohn16/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/ejohn16/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ejohn16/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "## Failure analysis - normalise/correct data\n",
    "\n",
    "# Load correction\n",
    "#failure['Load_correction'] = failure['Force_N'] - minf \n",
    "failure['Load_correction'] = failure.iloc[:, 5] - failure.iloc[0, 5]\n",
    "\n",
    "# Displacement correction \n",
    "#failure['Displacement_correction'] = failure['Displacement_mm'] - minf \n",
    "failure['Displacement_correction'] = failure.iloc[:, 4] - failure.iloc[0, 4]\n",
    "\n",
    "# Strain % \n",
    "failure['Strain_%'] = (failure['Displacement_correction']/sample_length)*100\n",
    "\n",
    "# Strain (mm)\n",
    "failure['Strain_mm'] = failure['Displacement_correction']/sample_length\n",
    "\n",
    "# Stress (Mpas)\n",
    "circumference_true = float(sample_metadata.iloc[0,9])\n",
    "# make use of float fuction to convert string from dataframe into a float value (number with a decimal place)\n",
    "failure['Stress_Mpas'] = failure['Load_correction']/circumference_true\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejohn16/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/ejohn16/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "/home/ejohn16/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "## Failure analysis - modulus columns\n",
    "\n",
    "# Need starting point for iteration in the modulus calculation\n",
    "# To calculate, find where stretch phase begins\n",
    "# Create index for whole failure sheet and just the stretch phase\n",
    "stretch_index = failure.loc[(failure.Cycle.str.contains('Stretch'))]\n",
    "stretch_index = np.array(pd.Index.tolist(stretch_index.index))\n",
    "failure_index = np.array(pd.Index.tolist(failure.index))\n",
    "\n",
    "# 'Stress @ 2positions before stretch as a moving value'\n",
    "# Subtract the first value in the whole failure sheet index from the point where the stretch cycle starts, then subtract an addition 2 \n",
    "modulus_start = (stretch_index[0] - failure_index[0]) - 2\n",
    "\n",
    "\n",
    "# Modulus (Mpa)\n",
    "for j in range(modulus_start,failure.shape[0]-5):\n",
    "    failure.loc[failure.index[j],'Modulus_mpa'] = ((failure.iloc[j+5,10] - failure.iloc[j-4,10])/(failure.iloc[j+5,9] - failure.iloc[j-4,9]))\n",
    "\n",
    "\n",
    "# Modulus - smooth \n",
    "failure['Modulus_smooth'] = failure['Modulus_mpa'].rolling(window=5).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the failure calculations the point at which failure occurs is calculated using the max value in the 'Stress_mpas' column. \n",
    "After this, the failure data is subsetted to remove everything after failure has taken place - as any values taken after would not be valid for the next steps of the analysis.\n",
    "From this newly subsetted data the max modulus value is calculated using the max value in the in 'Modulus_smooth' column. The smoothed modulus data is used because the unsmoothed data is too variable and a maximum value calculation would just calculate local behaviour rather than a true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Failure analysis - modulus calculations \n",
    "\n",
    "# Calculate the stress value at which failure occurs\n",
    "# Then use this to calculate strain, force and extension at which failure occurs\n",
    "failure_stress = failure['Stress_Mpas'].max()\n",
    "failure_strain_percent = failure.iloc[failure['Stress_Mpas'].argmax(), 8]\n",
    "failure_force = failure.iloc[failure['Stress_Mpas'].argmax(), 6]\n",
    "failure_extension = failure.iloc[failure['Stress_Mpas'].argmax(), 7]\n",
    "failure_time = failure.iloc[failure['Stress_Mpas'].argmax(), 2]\n",
    "\n",
    "#Subset failure column to remove everything after failure point for max modulus calculation\n",
    "subset_f = failure.iloc[0:failure['Stress_Mpas'].argmax(), ]\n",
    "\n",
    "# Calculate max modulus and stress/strain at max modulus on the newly subsetted version of the failure df\n",
    "# (The full failure df will be the one saved at the end)\n",
    "max_modulus = subset_f['Modulus_smooth'].max()\n",
    "stress_at_max_modulus = subset_f.iloc[subset_f['Modulus_smooth'].argmax(), 10]\n",
    "strain_at_max_modulus = subset_f.iloc[subset_f['Modulus_smooth'].argmax(), 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the processing and analysis has been carried out the outputs can be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create directory for output files\n",
    "\n",
    "if not os.path.exists(\"{}/{}\".format(dir, name)):\n",
    "    os.makedirs(\"{}/{}\".format(dir, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-conditioning output \n",
    "\n",
    "# Pre-conditioning summary tables\n",
    "\n",
    "force_data = [\n",
    "    ['General summary', ''],\n",
    "    ['Sample length', sample_length],\n",
    "    ['Minimum force', minf],\n",
    "    ['Maximum force', maxforce],\n",
    "    ['Maximum force cycle 1', maxforce_c1],\n",
    "    ['Maximum force cycle 5', maxforce_c5],\n",
    "    ['Stress-relaxtion', stress_relaxation]\n",
    "]\n",
    "force_table = AsciiTable(force_data)\n",
    "\n",
    "hysteresis_data = [\n",
    "    ['Hysteresis', 'Cycl 1-5'],\n",
    "    ['Positive value', hysteresis_positive],\n",
    "    ['Sum value', hysteresis_sum],\n",
    "    ['% value', percentage]\n",
    "]\n",
    "hysteresis_table = AsciiTable(hysteresis_data)\n",
    "\n",
    "\n",
    "# Processed precon table as csv\n",
    "precon.to_csv(\"{}/{}/precon_{}.csv\".format(dir, name, name), index=False)\n",
    "\n",
    "\n",
    "# Summary data as .txt file\n",
    "with open(\"{}/{}/precon_summary_{}.txt\".format(dir, name, name), 'w') as f:\n",
    "    print(\"Summary data for {} preconditioning...\\n\".format(name), file=f)\n",
    "    print(force_table.table, file=f) \n",
    "    print(hysteresis_table.table, file=f) \n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Failure output\n",
    "\n",
    "# Failure summary table\n",
    "modulus_data = [\n",
    "    ['Summary', ''],\n",
    "    ['Max modulus', max_modulus],\n",
    "    ['Stress at max modulus', stress_at_max_modulus],\n",
    "    ['Strain at max modulus', strain_at_max_modulus],\n",
    "    ['Failure stress (MPa)', failure_stress],\n",
    "    ['Failure strain (%)', failure_strain_percent],\n",
    "    ['Failure force (N)', failure_force],\n",
    "    ['Failure extension (mm)', failure_extension],\n",
    "    ['Failure time (s)', failure_time]\n",
    "]\n",
    "modulus_table = AsciiTable(modulus_data)\n",
    "\n",
    "# Processed failure table as csv\n",
    "failure.to_csv(\"{}/{}/failure_{}.csv\".format(dir, name, name), index=False)\n",
    "\n",
    "# Summary data as .txt file\n",
    "with open(\"{}/{}/failure_summary_{}.txt\".format(dir, name, name), 'w') as f:\n",
    "    print(\"Summary data for {} failure...\\n\".format(name), file=f)\n",
    "    print(modulus_table.table, file=f) \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Append current sample data to the overall summary\n",
    "all_sample_summary = all_sample_summary.append({\n",
    "    'File name': name, \n",
    "    'Date': sample_metadata.iloc[0,0], \n",
    "    'Sample ID': sample_metadata.iloc[0,1], \n",
    "    'Replicate number': sample_metadata.iloc[0,6], \n",
    "    'Sex': sample_metadata.iloc[0,3], \n",
    "    'Age': sample_metadata.iloc[0,4], \n",
    "    'Genotype': sample_metadata.iloc[0,5], \n",
    "    'Sample length': sample_length, \n",
    "    'Minimum force': minf, \n",
    "    'Maximum force': maxforce, \n",
    "    'Maximum force cycle 1': maxforce_c1, \n",
    "    'Maximum force cycle 5': maxforce_c5,\n",
    "    'Stress-relaxation': stress_relaxation, \n",
    "    'Rate of change of stress': stress_rate, \n",
    "    'Hysteresis sum value': hysteresis_sum, \n",
    "    'Hysteresis %': percentage, \n",
    "    'Smoothed hysteresis sum value': smooth_hysteresis_sum,\n",
    "    'Smoothed hysteresis %': smooth_percentage, \n",
    "    'Average diameter': sample_metadata.iloc[0,7], \n",
    "    'Circumference': sample_metadata.iloc[0,8], \n",
    "    'Circumference, true': sample_metadata.iloc[0,9],\n",
    "    'Max modulus': max_modulus, \n",
    "    'Stress at max modulus': stress_at_max_modulus,\n",
    "    'Strain at max modulus': strain_at_max_modulus, \n",
    "    'Failure stress (MPa)': failure_stress,\n",
    "    'Failure strain (%)': failure_strain_percent,\n",
    "    'Failure force (N)': failure_force,\n",
    "    'Failure extension (mm)': failure_extension,\n",
    "    'Failure time (s)': failure_time}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write summary table as output \n",
    "all_sample_summary.to_csv(\"{}/results_summary.csv\".format(dir), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The individual sample analysis is now complete. After this some plotting could be carried out. Here is some sample code, that can be modified as you need. Specify your x and y parameters then plot everything on the same graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot code \n",
    "\n",
    "x = failure['Strain_%']\n",
    "y1 = failure['Stress_Mpas']\n",
    "yhat = scipy.signal.savgol_filter(y1, 101, 3) # window size 201, polynomial order 3\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y1, 'k-', label='Raw data', color='black', alpha=0.2) # set transparency with 'alpha' parameter\n",
    "plt.plot(x, yhat, 'k-', label='Savgol', color='red')\n",
    "plt.xlabel('Strain (%)')\n",
    "plt.ylabel('Modulus (MPa)')\n",
    "plt.title('Stress vs Strain',fontsize=12)\n",
    "plt.legend()\n",
    "plt.savefig('test.png'.format(dir, name, name), bbox_inches='tight',dpi=300)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ea621206bf03f48c7f77a3fb1588963d8808e1ae8428dc6e66db249e7a2ec6d2"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('py36': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
